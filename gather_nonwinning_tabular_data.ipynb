{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc6878aa",
   "metadata": {},
   "source": [
    "# Gathering the Tabular Data for Non-Winning songs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46185ee4",
   "metadata": {},
   "source": [
    "I recently found a website called *[KPOPDB](https://www.kpopdb.net/en/)* that contains not only the initial music show wins data from 2019 but the competition for each win. This provides more data as to how close a win was, the competitveness of a given week, but more importantly gives us an idea of songs that have never won a music show despite being in contention of one. If it appears that I require more songs, I will resort to scraping a release chart of different comebacks to consider in my analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36245257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import re\n",
    "\n",
    "def sanitize_filename(name: str) -> str:\n",
    "    \"\"\"\n",
    "    Replace characters that aren't safe for filenames.\n",
    "    E.g., for \"Music Bank?\" -> \"Music_Bank_\"\n",
    "    \"\"\"\n",
    "    return re.sub(r'[^\\w\\-\\._ ]', '_', name)\n",
    "\n",
    "def scrape_kpopdb_year(year: int):\n",
    "    \"\"\"\n",
    "    Scrape https://www.kpopdb.net/en/wins.php?y={year}\n",
    "    and create one CSV per show (e.g., 'Music Bank') \n",
    "    containing a header row + all placements.\n",
    "    \"\"\"\n",
    "    base_url = \"https://www.kpopdb.net/en/wins.php\"\n",
    "    resp = requests.get(f\"{base_url}?y={year}\")\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "    \n",
    "    # Collect all <tr> in the main table\n",
    "    all_rows = soup.select(\"table.table tbody tr\")\n",
    "    \n",
    "    # We'll group our data by show name \n",
    "    # so we can write each show to its own CSV file\n",
    "    data_by_show = {}\n",
    "    \n",
    "    current_show_name = \"\"\n",
    "    current_date = \"\"\n",
    "    \n",
    "    for row in all_rows:\n",
    "        row_id = row.get(\"id\", \"\")\n",
    "        \n",
    "        # ---------------------------------------------------------------------\n",
    "        # 1) If this <tr> is the \"detail\" row, it has a nested <table>:\n",
    "        #    <tr id=\"detail###\">\n",
    "        #      <td colspan=\"...\">\n",
    "        #        <table> ... header row + data rows ... </table>\n",
    "        #      </td>\n",
    "        #    </tr>\n",
    "        # ---------------------------------------------------------------------\n",
    "        if row_id.startswith(\"detail\"):\n",
    "            nested_table = row.find(\"table\")\n",
    "            if not nested_table:\n",
    "                continue\n",
    "            \n",
    "            nested_rows = nested_table.find_all(\"tr\")\n",
    "            \n",
    "            # Grab the header row (first <tr>), then the detail rows\n",
    "            if len(nested_rows) > 0:\n",
    "                # 1A) Header row\n",
    "                header_cells = nested_rows[0].find_all([\"th\", \"td\"])\n",
    "                header_texts = [hc.get_text(strip=True) for hc in header_cells]\n",
    "                \n",
    "                # Store the header in data_by_show if not already stored\n",
    "                show_key = (current_show_name or \"Unknown Show\").strip()\n",
    "                if show_key not in data_by_show:\n",
    "                    data_by_show[show_key] = {\n",
    "                        \"header\": [\"Show\", \"Date\"] + header_texts,  # Prepend Show & Date\n",
    "                        \"rows\": []\n",
    "                    }\n",
    "                \n",
    "                # 1B) Subsequent rows are actual data\n",
    "                for detail_row in nested_rows[1:]:\n",
    "                    data_cells = detail_row.find_all(\"td\")\n",
    "                    if data_cells:\n",
    "                        row_texts = [dc.get_text(strip=True) for dc in data_cells]\n",
    "                        # Build the final row with show + date + detail columns\n",
    "                        final_row = [current_show_name, current_date] + row_texts\n",
    "                        \n",
    "                        data_by_show[show_key][\"rows\"].append(final_row)\n",
    "        \n",
    "        # ---------------------------------------------------------------------\n",
    "        # 2) If this <tr> is a normal row, it should contain\n",
    "        #    something like <td>Music Bank</td><td>2024-03-10</td>\n",
    "        # ---------------------------------------------------------------------\n",
    "        else:\n",
    "            cells = row.find_all(\"td\")\n",
    "            if len(cells) >= 2:\n",
    "                current_show_name = cells[2].get_text(strip=True)\n",
    "                current_date = cells[1].get_text(strip=True)\n",
    "                \n",
    "                # If you need more columns from this row, you can parse them here as well.\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # After collecting all data for the year, write them out as separate CSVs\n",
    "    # one CSV per show program\n",
    "    # -------------------------------------------------------------------------\n",
    "    for show_name, show_data in data_by_show.items():\n",
    "        filename = f\"{year}_{sanitize_filename(show_name)}.csv\"\n",
    "        print(f\"Writing {filename} with {len(show_data['rows'])} rows...\")\n",
    "        \n",
    "        with open(filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(show_data[\"header\"])  # Write the single header row\n",
    "            writer.writerows(show_data[\"rows\"])   # Write all data rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae80182c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 2025_Thu.csv with 27 rows...\n",
      "Writing 2025_Wed.csv with 35 rows...\n",
      "Writing 2025_Tue.csv with 15 rows...\n",
      "Writing 2025_Sun.csv with 41 rows...\n",
      "Writing 2025_Sat.csv with 33 rows...\n",
      "Writing 2025_Fri.csv with 32 rows...\n"
     ]
    }
   ],
   "source": [
    "test = scrape_kpopdb_year(2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c8eb053",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "essentia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
